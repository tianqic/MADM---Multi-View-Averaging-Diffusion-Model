### [MADM: 2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction](https://arxiv.org/abs/2406.08374)
https://arxiv.org/abs/2406.08374

**Tianqi Chen, Jun Hou, Yinchi Zhou, Huidong Xie, Xiongchao Chen, Qiong Liu, Xueqi Guo, Menghua Xia, James S. Duncan, Chi Liu, Bo Zhou**

This repository contains the official implementation of **MADM**, a novel diffusion-based framework for ultra-low-dose PET reconstruction. MADM significantly reduces radiation exposure by eliminating the need for additional CT scans and improves image quality through multi-view integration and attenuation correction.

<p align="center">
  <img src="figure/Figure_pipline.png" alt="MADM Pipeline" width="1000"/>
</p>

---

## ğŸ”¬ Project Description

**MADM (Multi-view Attenuation-aware Diffusion Model)** is designed to generate high-quality AC standard-count PET(AC-SDPET) directly from the NAC low-count PET(NAC-LDPET) in 3D with reasonable computation resources without relying on CT scans for attenuation correction. Our method integrates:
- **2.5D Multi-View Diffusion** Lightweight, consistent 3D generation from 2.5D slice in different views.
- **Prior-Guided Denoising** Incorporates CNN-based prior to accelerate diffusion and improve accuracy.
---

## Data preparation
### Paired translation task
For datasets that have paired image data, the path should be formatted as:
```yaml
/path/to/data_root/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 5NAC/
â”‚   â”‚   â”œâ”€â”€ patient001_5_NAC.nii
â”‚   â”‚   â”œâ”€â”€ patient002_5_NAC.nii
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 100AC/
â”‚   â”‚   â”œâ”€â”€ patient001_100_AC.nii
â”‚   â”‚   â”œâ”€â”€ patient002_100_AC.nii
â”‚   â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ 5NAC/
â”‚   â””â”€â”€ 100AC/
â””â”€â”€ test/
    â””â”€â”€ 5NAC/

```
For the prior data want to load, the path should be formatted as:
```yaml
/path/to/load_prior_root/
â”œâ”€â”€ patient001_umap_pred.nii
â”œâ”€â”€ patient002_umap_pred.nii
â”œâ”€â”€ patient003_umap_pred.nii
â””â”€â”€ ...
```

To perform inference using MADM across multiple views (2.5D: x, y, z), you should train and save a model for each axis independently. During testing or sampling, each model should be loaded from its respective checkpoint.

Recommended Checkpoint Directory Structure
```yaml
/path/to/model_checkpoints/
â”œâ”€â”€ model_x.pt
â”œâ”€â”€ model_y.pt
â””â”€â”€ model_z.pt
```
---

## Train and Test
### Training
To train the MADM diffusion model on your 2.5D PET dataset, run the following command: 

```yaml
python train.py
```
Make sure to train a separate model for each axis (x, y, z) using different --train_axis and checkpoint folders. These will later be used for multi-view inference.

If you wish to continue training, specify the model checkpoint path --resume_checkpoint in the train part:
```yaml
python train.py --resume_checkpoint path/to/model_ckpt
```

### Testing
Once training is complete, use the testing script to generate AC-SDPET outputs from NAC-LD input using all trained view models.
```yaml
python sample_3D.py --model_axis x y z --load_prior_root /path/to/load_prior_root --model_root /path/to/ model_checkpoints --save_root /path/to/save_dir
```

### Output
Predictions are saved in NIfTI format under:
```yaml
/path/to/save_dir
â””â”€â”€ adj#_models_views/
    â”œâ”€â”€ *_single/
    â”‚   â””â”€â”€ patient001_pred_0.nii
    â””â”€â”€ *_comb/
        â””â”€â”€ patient001_pred.nii  â† averaged output across samples
```

Each prediction is clipped to non-negative values and saved using the patient ID from the test set. The *_comb directory contains the final averaged predictions per subject.


## Acknowledgement
Our code is implemented based on Guided Diffusion

[Guided Diffusion](http://arxiv.org/abs/2105.05233) 
